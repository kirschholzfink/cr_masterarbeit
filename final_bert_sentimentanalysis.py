# -*- coding: utf-8 -*-
"""FINAL_BERT_SentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Mz84P_MKuYqtim6oTzeBl0KSbOL3vvz

**To run all code cells, press Ctrl+F9 or click 'Runtime' - 'Run all'.**
"""

'''
!pip
install - q - U
watermark
'''
'''
!pip
install - qq
transformers
'''

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext watermark
# %watermark -v -p numpy,pandas,torch,transformers

from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup
import torch

import csv
from collections import defaultdict

import numpy as np
import pandas as pd
import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import confusion_matrix, classification_report

from torch import nn
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# %matplotlib inline
# %config InlineBackend.figure_format='retina'

sns.set(style='whitegrid', palette='muted', font_scale=1.2)

COLOR_PALETTE = ["#01BEFE", "#FFDD00", "#FF7D00", "#FF006D", "#ADFF02", "#8F00FF"]

sns.set_palette(sns.color_palette(COLOR_PALETTE))

rcParams['figure.figsize'] = 12, 8


class TrainingSet(Dataset):

    def __init__(self, reviews, targets, tokenizer, max_len):
        self.reviews = reviews
        self.targets = targets
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.reviews)

    def __getitem__(self, item):
        review = str(self.reviews[item])
        target = self.targets[item]

        encoding = self.tokenizer.encode_plus(
            review,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            return_attention_mask=True,
            return_tensors='pt',
            truncation=True
        )

        return {
            'review_text': review,
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'targets': torch.tensor(target, dtype=torch.long)
        }


class Preprocessor:

    def __init__(self, dataset, tokenizer, max_comment_length, batch_size):
        self.dataset = dataset
        self.tokenizer = tokenizer
        self.max_comment_length = max_comment_length
        self.batch_size = batch_size

    def split_data_for_crossval(self, testset_size):
        trainset, testset = train_test_split(
            self.dataset,
            test_size=testset_size,
            random_state=RANDOM_SEED
        )
        return trainset, testset

    def split_data_for_training(self, testset_size):
        trainset, testset = train_test_split(
            self.dataset,
            test_size=testset_size,
            random_state=RANDOM_SEED
        )
        valset, testset = train_test_split(
            testset,
            test_size=0.5,
            random_state=RANDOM_SEED
        )
        return trainset, testset, valset

    def create_data_loader(self, subset):
        ds = TrainingSet(
            reviews=subset.content.to_numpy(),
            targets=subset.sentiment.to_numpy(),
            tokenizer=self.tokenizer,
            max_len=self.max_comment_length
        )

        return DataLoader(
            ds,
            batch_size=self.batch_size,
            num_workers=2,
        )


class SentimentClassifier(nn.Module):

    def __init__(self, n_classes):
        super(SentimentClassifier, self).__init__()
        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)
        self.drop = nn.Dropout(p=0.1)
        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)

    def forward(self, input_ids, attention_mask):
        _, pooled_output = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            return_dict=False
        )
        output = self.drop(pooled_output)
        return self.out(output)


class Trainer:

    def __init__(self, model, loss_fn, optimizer, device, scheduler):
        self.model = model
        self.loss_fn = loss_fn
        self.optimizer = optimizer
        self.device = device
        self.scheduler = scheduler

    def train_epoch(self, data_loader, n_examples):

        model = self.model.train()

        losses = []
        correct_predictions = 0
        counter = 0

        for d in data_loader:
            input_ids = d["input_ids"].to(self.device)
            attention_mask = d["attention_mask"].to(self.device)
            targets = d["targets"].to(self.device)
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            _, preds = torch.max(outputs, dim=1)
            loss = self.loss_fn(outputs, targets)
            correct_predictions += torch.sum(preds == targets)
            losses.append(loss.item())
            loss.backward()
            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            self.optimizer.step()
            self.scheduler.step()
            self.optimizer.zero_grad()

        return correct_predictions.double() / n_examples, np.mean(losses)

    def eval_model(self, data_loader, n_examples):

        model = self.model.eval()

        losses = []
        correct_predictions = 0

        with torch.no_grad():
            for d in data_loader:
                input_ids = d["input_ids"].to(self.device)
                attention_mask = d["attention_mask"].to(self.device)
                targets = d["targets"].to(self.device)

                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask
                )
                _, preds = torch.max(outputs, dim=1)

                loss = self.loss_fn(outputs, targets)

                correct_predictions += torch.sum(preds == targets)
                losses.append(loss.item())

        return correct_predictions.double() / n_examples, np.mean(losses)


class Evaluator:

    def get_predictions(self, model, data_loader):
        review_texts = []
        predictions = []
        prediction_probs = []
        real_values = []

        with torch.no_grad():
            for d in data_loader:
                texts = d["review_text"]
                input_ids = d["input_ids"].to(device)
                attention_mask = d["attention_mask"].to(device)
                targets = d["targets"].to(device)

                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask
                )
                _, preds = torch.max(outputs, dim=1)

                probs = F.softmax(outputs, dim=1)

                review_texts.extend(texts)
                predictions.extend(preds)
                prediction_probs.extend(probs)
                real_values.extend(targets)

        predictions = torch.stack(predictions).cpu()
        prediction_probs = torch.stack(prediction_probs).cpu()
        real_values = torch.stack(real_values).cpu()
        return review_texts, predictions, prediction_probs, real_values

    def show_confusion_matrix(self, confusion_matrix):
        hmap = sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="Blues")
        hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')
        hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')
        plt.ylabel('True sentiment')
        plt.xlabel('Predicted sentiment');


RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""**Downloading training sets:**"""

# !gdown --id 17DrX3TrM1UgrdfLIn6zdfkARdcGe6cCL4

df = pd.read_csv("trainingset_full.csv")

class_names = ['non-negative', 'negative']

PRE_TRAINED_MODEL_NAME = 'bert-base-cased'
tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)

"""Defining the maximum input sequence length to the BERT model."""

MAX_COMMENT_LENGTH = 512

"""**Defining the batch size:**"""

BATCH_SIZE = 2

"""**Defining the number of training epochs:**"""

EPOCHS = 7

"""**Defining the learning rate for the optimization algorithm:**"""

LEARNING_RATE = 2e-5

"""**Creating a preprocessor instance:**"""

preprocessor = Preprocessor(
    df,
    tokenizer,
    max_comment_length=MAX_COMMENT_LENGTH,
    batch_size=BATCH_SIZE
)

"""**Defining the loss function, including weights:**"""

negatives = (df['sentiment'] == 0).sum()
positives = (len(df)) - negatives
weight = torch.tensor([float(positives / negatives), float(positives / positives)])

loss_fn = nn.CrossEntropyLoss(weight=weight).to(device)

"""# **TRAINING:**

**Splitting the dataset into a training set (90%), validation set (5%) and test set (5%):**
"""

TEST_SET_SIZE = 0.1

df_train, df_test, df_val = preprocessor.split_data_for_training(TEST_SET_SIZE)

train_data_loader = preprocessor.create_data_loader(df_train)
test_data_loader = preprocessor.create_data_loader(df_test)
val_data_loader = preprocessor.create_data_loader(df_val)

model = SentimentClassifier(len(class_names))
model = model.to(device)

optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)
total_steps = len(train_data_loader) * EPOCHS

scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=1000,
    num_training_steps=total_steps
)

trainer = Trainer(
    model,
    loss_fn,
    optimizer,
    device,
    scheduler
)

"""**Training model:**"""

# %%time

history = defaultdict(list)
best_accuracy = 0

for epoch in range(EPOCHS):

    print(f'Epoch {epoch + 1}/{EPOCHS}')
    print('-' * 10)

    train_acc, train_loss = trainer.train_epoch(train_data_loader, len(df_train))

    print(f'Train loss {train_loss} accuracy {train_acc}')

    val_acc, val_loss = trainer.eval_model(
        val_data_loader,
        len(df_val)
    )

    print(f'Val   loss {val_loss} accuracy {val_acc}')
    print()

    history['train_acc'].append(train_acc)
    history['train_loss'].append(train_loss)
    history['val_acc'].append(val_acc)
    history['val_loss'].append(val_loss)

    # Saving the state of the best model
    if val_acc > best_accuracy:
        torch.save(model.state_dict(), 'best_model_state.bin')
        best_accuracy = val_acc

"""**Plotting training vs. validation accuracy:**"""

plt.plot(history['train_acc'], label='train accuracy')
plt.plot(history['val_acc'], label='validation accuracy')

plt.title('Training history')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.ylim([0, 1]);

"""**To proceed with a model that was trained on the full dataset, uncomment the lines in the following cell:**"""

# !gdown --id 1Dt69yhiZ19Z8Lz4jIXanJH-hkpRrGRpS
# model = SentimentClassifier(len(class_names))
# model.load_state_dict(torch.load('fully_trained_model.bin'))
# model = model.to(device)

"""**Generating classification report:**"""

evaluator = Evaluator()

y_review_texts, y_pred, y_pred_probs, y_test = evaluator.get_predictions(model, test_data_loader)
"""
Caution: If you test this function with a small dataset, a 
'ValueError: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter'
might occur.
This is usually due to split test datasets that are too small, and using a larger test dataset will help.
"""

print(classification_report(y_test, y_pred, target_names=class_names))

"""**Generating confusion matrix:**"""

cm = confusion_matrix(y_test, y_pred)
df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)
evaluator.show_confusion_matrix(df_cm)

"""# **CROSS VALIDATION:**

**Splitting the dataset into a training set (90%) and validation set (10%):**
"""

VAL_SET_SIZE = 0.1

df_train, df_val = preprocessor.split_data_for_crossval(VAL_SET_SIZE)

"""**Defining number of folds for cross validation:**"""

K_FOLDS = 10

kfold = KFold(n_splits=K_FOLDS, shuffle=True)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
history = defaultdict(list)
cross_val_results = {}

for fold, (train_ids, test_ids) in enumerate(kfold.split(df_train)):

    print(f'FOLD {fold + 1}/{K_FOLDS}')
    print('-' * 20)

    train_data_loader = preprocessor.create_data_loader(df_train)
    val_data_loader = preprocessor.create_data_loader(df_val)

    model = SentimentClassifier(len(class_names))
    model = model.to(device)

    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)
    total_steps = len(train_data_loader) * EPOCHS

    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=1000,
        num_training_steps=total_steps
    )

    trainer = Trainer(
        model,
        loss_fn,
        optimizer,
        device,
        scheduler
    )

    evaluator = Evaluator()

    for epoch in range(EPOCHS):
        print(f'Epoch {epoch + 1}/{EPOCHS}')
        print('-' * 10)

        train_acc, train_loss = trainer.train_epoch(train_data_loader, (K_FOLDS - 1) * (len(df_train) / K_FOLDS))

        print(f'Train loss {train_loss} accuracy {train_acc}')

        val_acc, val_loss = trainer.eval_model(
            val_data_loader,
            (len(df_train) / K_FOLDS)
        )

        print(f'Val   loss {val_loss} accuracy {val_acc}')
        print()

        history['train_acc'].append(train_acc)
        history['train_loss'].append(train_loss)
        history['val_acc'].append(val_acc)
        history['val_loss'].append(val_loss)

    print('Training process has finished. Saving trained fold model.')

    torch.save(model.state_dict(), f'saved_fold_model0{fold + 1}.bin')

    print('Starting to evaluate this fold...')
    print()

    fold_acc, fold_loss = trainer.eval_model(
        val_data_loader,
        (len(df_train) / K_FOLDS)
    )

    print(f'Fold validation loss: {fold_loss}, Fold accuracy: {fold_acc}')
    print()

    print(f'Saving fold history0{fold + 1}...')
    print()

    write_to_csv = csv.writer(open(f'history_fold0{fold + 1}.csv', "w"))
    for key, val in history.items():
        write_to_csv.writerow([key, val])

    cross_val_results[fold] = fold_acc

    y_review_texts, y_pred, y_pred_probs, y_test = evaluator.get_predictions(
        model,
        val_data_loader
    )

    print(classification_report(y_test, y_pred, labels=[0, 1],
                                target_names=class_names))

print()

print(f'K-FOLD CROSS VALIDATION RESULTS FOR {K_FOLDS} FOLDS')
print('-' * 10)

sum = 0.0
for key, value in cross_val_results.items():
    print(f'Fold {key + 1}: {value} %')
    sum += value
print(f'Average: {sum / len(cross_val_results.items())} %')